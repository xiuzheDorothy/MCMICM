{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一次参加美赛的记录\n",
    "> 2020年是我第一次参加美赛，为此寒假特地准备了一个多月，庆幸的是学的很多东西都确实用上了，算是学有所用吧。但也发现有许多东西没有接触过，最后复盘也发现很多东西在建模的时候没有详细的考虑，许多涉及到Stochastic Process的知识没有学习过（听闻知乎大佬的回答说d小问可以考虑一些随机过程的方法[[1]](https://www.zhihu.com/question/377089279/answer/1062589336)，但是我这学期才开随机过程，只学了一点皮毛）。d小题还想到了一个从信号与系统中LTI离散系统受到启发的差分方程模型，但奈何这方面的具体知识也不是太熟，所以只是一个很简单的模型，甚至可能漏洞百出。希望下次能够再接再厉吧，总体来说还是一次很有意思经历，数模尤其是C题还挺有意思的，能够很好的跟自己的专业知识结合起来。\n",
    "\n",
    "## 问题回顾\n",
    "### 原题\n",
    "在其创建的在线市场中，亚马逊为客户提供了一个评价和审查购买的机会。个人评级——称为“星级评级”（**star ratings**）——允许购买者使用1(低评级，低满意度)到5(高评级，高满意度)的等级来表达他们对产品的满意度。此外，客户可以提交基于文本的消息—称为“评论”（**reviews**）—来表达关于产品的进一步意见和信息。其他客户可以在这些评论中提交对他们自己的产品购买决策是否有帮助的评级——称为“帮助度评级”（**helpfulness rating**）。公司利用这些数据来洞察他们所参与的市场、参与的时机以及产品设计特性选择的潜在成功。\n",
    "\n",
    "阳光公司计划在网上市场推出并销售三种新产品:微波炉（microwave oven）、婴儿奶嘴（baby pacifier）和电吹风（ hair dryer）。他们聘请你的团队作为顾问，以确定过去客户提供的与其他竞争产品相关的评级和评论中的关键模式、关系、度量和参数，以<font color=red>1)告知他们的在线销售策略，2)确定可能提高产品吸引力的重要设计特性。</font>阳光公司过去曾使用数据来告知销售策略，但他们以前从未使用过这个特殊的数据\n",
    "\n",
    "关键模式、关系、度量和参数:**key patterns, relationships, measures, and parameters**\n",
    "\n",
    "为了帮助您，Sunshine的数据中心为您提供了三个数据文件：hair_dryer.tsv, microwave.tsv, and pacifier.tsv. 这些数据代表了在数据中显示的时间段内亚马逊市场上销售的微波炉、婴儿奶嘴和吹风机的客户提供的评级和评论。我们提供了数据标签定义的术语表，提供的数据文件包含您应该用于此问题的唯一数据。\n",
    "\n",
    "**要求：**\n",
    "1. 分析所提供的三个产品数据集，以识别，描述和支持数学证据，找出**星级，评论和帮助等级（helpfulness ratings）**之内和之间有意义的定量和/或定性模式，关系，度量和参数，将帮助阳光公司在他们的三个新的在线市场产品提供成功。（机翻警告）\n",
    "\n",
    "2. 使用您的分析来解决以下具体问题和阳光公司营销总监的要求:\n",
    "    1. 基于评论和评级确定一个**度量标准 （data measures）**以便于当该公司将产品投放到市场后的追踪\n",
    "    2. 识别并讨论每个数据集中基于时间的度量和模式，这些度量和模式可能表明产品在在线市场中的声誉正在增加或减少\n",
    "    3. 确定基于文本的度量方法和基于评级的度量方法的组合，以最好地指示潜在的成功或失败的产品。\n",
    "    4. 特定的评星会引发更多的评论吗?例如，在看到一系列的低星级评价后，客户更有可能写一些评论吗?\n",
    "    5. 基于文本的评论的特定质量描述符，如“热情”、“失望”等，是否与评级水平密切相关?\n",
    "    \n",
    "3. 给阳光公司的市场总监写一封一到两页的信，总结你的团队的分析和结果。包括你的团队最自信地向市场总监推荐的结果的具体理由:\n",
    "\n",
    "Your submission should consist of:\n",
    "- 单页汇总表\n",
    "- 目录\n",
    "- 二页的信\n",
    "\n",
    "注意:参考列表和任何附录不计入页面限制，应在完成解决方案后显示。你不应该使用未经授权的图像和材料，其使用受到版权法的限制。确保你在报告中引用了你的观点和材料。\n",
    "\n",
    "- Helpfulness Rating:在决定是否购买某一产品时，对某一产品的评价是否有价值的一个指标\n",
    "- Review: 对产品的书面评价\n",
    "- Star Rating: 在一个允许人们用若干颗星来评价一个产品的系统中给出的分数。\n",
    "\n",
    "### 题目分析\n",
    "第一个小题看起来十分费解，结合原文共同理解：*Analyze the three product data sets provided to identify, describe, and support with mathematical evidence, meaningful quantitative and/or qualitative patterns, relationships, measures, and parameters within and between star ratings, reviews, and helpfulness ratings that will help Sunshine Company succeed in their three new online marketplace product offerings.*\n",
    "- Analyze the three product data sets provided：分析所提供（provided）的三个数据\n",
    "- to identify, describe, and support with ... ：分析三个数据集，目的是为了identify和describe这些数据集，并且你的identify和describe需要以下这些东西的支持：\n",
    "- support with mathematical evidence, meaningful quantitative and/or qualitative patterns, relationships, measures, and parameters：你的identify和describe需要以下这些东西的支持：数学意义上的证据，有意义的定量和/或定性模式，关系，度量和参数\n",
    "- within and between star ratings, reviews, and helpfulness ratings：这些模式关系度量参数是在星级、评论和帮助度之内和之间的（within and between）\n",
    "\n",
    "总结就是这么个意思：分析所提供（provided）的三个数据，目的是为了identify和describe这些数据集，并且你的identify和describe需要以下这些东西的支持：在**星级、评论和帮助度之内和之间**的（within and between）数学意义上的证据，有意义的定量和/或定性模式，关系，度量和参数。换而言之就是用数学的语言描述这三个数据集间三个维度之间或之内的关系，也就是数据分析的第一步，大概认识数据。\n",
    "\n",
    "mathematical evidence是什么意思？mathematical 词典上的解释是*adj. 数学的，数学上的；精确的*，不论是哪一种解释都差不多，即必须精确、量化、数字化地描述数据。\n",
    "\n",
    "第二题：\n",
    "- 基于评论和星级确定一个度量标准。我们团队的理解是，确定一个合并了两个指标的一个新的度量标准，可以用来衡量当前商品的情况。一种思路是新的指标的不同数字反映了产品的情况（一维的），就像一个数轴，在某个范围商品便认为是处于某种状态的（卖得好或不好）。我们队伍的度量标准是二维的平面图，处于我们划定的椭圆之内的产品是大卖的。\n",
    "![](https://s1.ax1x.com/2020/03/15/81HzLt.png)\n",
    "- 第二小题需要引入时间维度，很明显的一个时间序列问题。我们队采用的方法是二次指数平滑法，因为这一部分是我另一个队友做的，所以我了解的不是很多，而且我也挺懒的，接触的比较多的是VAR、ARIMA这种，也没细看他的公式。。。\n",
    "- *确定基于文本的度量方法和基于评级的度量方法的组合*，很明显我们需要对文本提炼出一种度量方法，以定量的描述出文本中携带的信息，这一个点可以说是全题的关键了，我们队伍的核心都在如何量化评论上。我想了一个在**高斯过程**的基础上还原真实情况的模型，以预测不同类型产品的大概走势。*以最好地指示潜在的成功或失败的产品*：什么是<font color=red>潜在</font>?说实话我在构建模型时没有仔细考虑这个问题，只想的是通过一个联合了文本和评星的方程，可以通过评星的多少文本指标的高低反应不同的销售趋量，但是看了一个**大佬的博客**[[2]](https://wmathor.com/index.php/archives/1421/)之后发现他认为的潜在是：发现处于要火但是还未火状态的产品，就像我们经常说一个up主是“好看不火”，因此这是一个潜在的up主。而不是我想的预测未来的走势，通过当前的评论、星级发现以后哪些产品有销量上升下降的趋势。\n",
    "> 那么问题来了，怎么定义潜在？怎么定义成功（失败）。我是这么想的，将各个品牌按照销量从小到大排序，排序处于 1/4 和 3/4 内的都是潜在品牌。1/4 和 3/4 其实是统计学中比较常见的两个点，一个是下四分位数，一个是上四分位数，这俩数都是有具体意义的，但是我们可以先感性理解一下,假如一个产品的销量处于 3/4，他还能叫做潜在吗，这明明就是很火的产品好么；假如一个产品的销量处于 1/4，销量实在是太小了，可能也才 10 件左右，不可能看得出来潜力的。找出处于 1/4 和 3/4 的品牌后，画出它们的好评率和差评率，好评率高 & 差评率低的当然就是具有成功可能性的潜在产品[[2]](https://wmathor.com/index.php/archives/1421/)\n",
    "- 特定的评星会引发更多的评论吗?队友做的，他好像是直接肉眼看出来的。。。我拿数据做了一个差分，更多评论就是>0，更多评星也是>0，然后算一下相关系数，有那么一丢丢关联程度吧。。。80%置信水平可以认为相关的那种\n",
    "- 基于文本的评论的特定质量描述符，如“热情”、“失望”等，是否与评级水平密切相关? 一拿到这个题我的想法就是关联规则学习（因为寒假学机器学习的时候特别迷这玩意，看到题的时候老琢磨怎么给用上去），首先把文本中的特定描述符提取出来，筛去停用词（stop words），然后星级和特定描述符形成一个项集例如：\\{5,excellent\\}，\\{1,junk\\}，这就是两个不同特定描述符的部分项集，然后找出该描述符的星级分布，可见其关联性。\n",
    "\n",
    "我们队伍的流程图如下：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/81xpcD.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "不知道爬数据的人是故意提升难度的还是咋，脏数据一大堆。有很多不属于该类别的数据被放入了这个类别：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/81xNgU.png\" width=\"200\"/>\n",
    "</center>\n",
    "例如在pacifier中发现了宝宝牙刷，hair dryer中发现了镊子，microwave中发现了洗衣机、抽烟机等等，于是把这些数据删去，删去方法可以用python字符串匹配，也可以excel直接用文本筛选功能（越来越觉得excel好用了）。以及会有一些数据错行，比如当筛选是否为vine用户时会发现串行现象，因为不是很多，考虑人工填补或者删去之类的。\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/81z5yF.png\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "还有一个有争议的问题是**verified_purchase (string)**，是否为有效购买，我们队伍理所应当认为只有有效购买之后的评论才有价值，如果没有真的买产品那评论肯定是不负责任的，水军啊收钱了之类的。但我后来发现一个问题：vine用户和非有效购买有很高的重叠性（白嫖石锤了），这导致我们直接舍弃了vine用户的特殊价值，本来还想就着vine用户做一番文章，但没办法，我们认为有效购买的评论才有价值。\n",
    "\n",
    "删去购买较少的产品，有的产品通常只有一两条评论，这些产品的评星通常没有很大的价值，还会扰乱我们的分析，所以在分析评星和其他指标关系的时候将其删去\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/83pPuF.png\" width=\"200\"/><img src=\"https://s1.ax1x.com/2020/03/15/83pm36.png\" width=\"200\"/>\n",
    "</center>上图为删除前，下图为删除后（review score是后来计算出来的一个指标）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本量化\n",
    "> - review_headline (string)：评论的标题\n",
    "> - review_body (string)：The review text\n",
    "> - review_date (bigint)：The date the review was written\n",
    "> - helpful_votes (int)：Number of helpful votes\n",
    "> - total_votes (int)：Number of total votes the review received 评论收到的所有投票：包括有帮助与无帮助\n",
    "\n",
    "我们假定：一条评论的标题是全部内容的概括，一条评论的主体是标题的补充。例如一条评论标题为“五星好评”，主体则会是为什么好评，产品好在哪里balabala，因此分别分析。我们将一条评论分为三个维度，分别是信息丰度：（Information Abundance），情感取向（Emotional Orientation）和评论可靠度（Review Reliability），分别取自body的除开空格、重复字符之后的字符串长度，标题的情感词和helpful_votes/max(total_votes)\n",
    "\n",
    "我们认为评论的长度往往能反映一条评论的价值所在：\n",
    "> Judith A argues that the length of A comment is related to the enthusiasm of the reviewer. The longer the review, the more information it contains, which can help customers understand the product better and thus affect sales.\n",
    "> （Chevalier J AMayzlin D.The effect of word of mouth on sales;Online book reveiw[J].Journal of Marketing Research,2006,43(3):345.）\n",
    "\n",
    "我傻了,我发现我们论文里这个地方的引用没写引用数字。。。\n",
    "\n",
    "情感取向是我挑选出headline中的情感词进行手动排序的，看网上有人说可以引入NLP库中的情感分析库，我始终觉得这个属于引入外部数据，所以没用，还是自己打分好了。\n",
    "\n",
    "我们采用层次分析法的方式为这三个指标赋予不同的权重，最终得到一个综合的指标review score。\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/83ihS1.png\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "> We set IO is the coefficient of importance of Information Abundance, IE is the coefficient of importance of Emotional Orientation, IR is the coefficient of importance of Review Reliability, l is the maximum characteristic root of the A matrix.\n",
    "\n",
    "最终得到各指标占比以计算review score：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/83iOfA.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析\n",
    "### 定性与定量分析\n",
    "对于每一种商品，我们首先计算出该商品的销售量，然后取明星评级的平均值作为该商品的明星评级，最终得到明星评级与销售量的关系如下图所示:\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/83qhwt.png\" width=\"800\"/>\n",
    "</center>\n",
    "\n",
    "情感取向和评星之间的关系\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88S7sU.png\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "关于review score和rating联合起来的与销量之间的关系，我们使用了SVR回归模型，希望发现它们之间的关系，于是发现部分商品比如pacifier确实有很强的关联性，但也有些并不有明显的关联\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88p26K.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "### 基于星级与评价的联合度量模型\n",
    "我们团队先对整体数据进行了一个大概判断：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/889Cpq.png\" width=\"400\"/>\n",
    "</center>\n",
    "认为四星即以上是高评价产品，二星及以下是低评价产品，以及它们的评星平均值，可以说低于这个值的都是不太好的产品。\n",
    "\n",
    "进一步分析，我构想了一个修正的one-class SVM模型，one class SVM常被用于异常检测，在我之前的博客中有提到过\n",
    "> [2019美赛C题——论文阅读与思考（I）](https://xiuzhedorothy.gitee.io/2020/02/25/2019-mei-sai-c-ti-lun-wen-yue-du-yu-si-kao-i-1/)\n",
    "\n",
    "> 另附引文出处：[Python机器学习笔记——One Class SVM](https://www.cnblogs.com/wj-1314/p/10701708.html)\n",
    "\n",
    "想法是将那些属于低销量产品的点看做异常点，然后用一个椭圆将好的产品圈起来，圈外的产品我们认为是不合格的。为什么是修正的one-class SVM呢，因为我想这是一个有关销量的一分类问题，而不是单纯的评星和评价度量，我希望销量越高的产品越有聚集在一起的可能性，销量越低的产品越有疏远的可能性，于是在原来的欧式距离上加上了一个**销量的倒数**，实现了这么一个要求：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88ClPs.png\" width=\"400\"/>\n",
    "</center>\n",
    "其实上式就是在原来的one-class SVM上加上了$S_i$项，最终也确实能够跑出一点效果，如下图所示：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88C5RI.png\" width=\"200\"/>\n",
    "</center>\n",
    "小椭圆和大椭圆分别是$C$设置为0.5和0.2的时候的结果，分别反映了50%作为异常点和20%作为异常点。也就是说：处于小椭圆范围内的可以说是卖的非常好的，大椭圆外的产品则是极为差劲的。\n",
    "\n",
    "### 基于时间的分析\n",
    "在这里我们用了二次指数平滑法通过以往的评星对今后的评星趋势做了一个预测。由于不是我做的，而且这种东西比较固定，网上一查一堆，不再赘述原理。\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88PGYd.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "说一点自己后来的思考吧（可能有点冒犯队友了，当然做题不就是不断冒犯否定对方看法最终找到正确的过程吗）：原题是*识别并讨论每个数据集中基于时间的度量和模式，这些度量和模式可能表明产品在在线市场中的声誉正在增加或减少*，赛后我在想，这一问应该不单单是一个时间序列处理问题，不然太没水平了，我觉得应该得到的是一个时间作为自变量而因变量是一个新的指标的模型，而这个新的指标是能够从侧面反映声誉的变化的，声誉是它在轴上平移后的函数（因为还是类似于预测）。还有“声誉”就是评星吗，这也是一个值得商榷的问题，声誉会不会更多的指向评论里面人的评价而非评星？所以是不是应该把变量换成review score或者更进一步只分析review body？这都是一开始考虑问题的时候缺失的地方。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于高斯过程还原销量的真实情况\n",
    "> 模型的这一部分是我觉得最天马牛逼的地方，也是一直最愿意拿出来说的部分。但实际上最后想想也还是太naive了，属于硬套而且也没用上什么比较专业一点的分析方法，模型的准确性也没没有验证。不过很好的一点是这个模型很具有独创性，自己吃饭的时候突然想出来的，然后立马吃完饭开始试验。我倒希望整个论文里能出现更多这种具有独创性的东西，而不是死套现成的机器学习或者统计学算法，挺没劲的。\n",
    "\n",
    "那么这个基于高斯过程的模型是什么呢，问题是让*确定基于文本的度量方法和基于评级的度量方法的组合，以最好地指示潜在的成功或失败的产品*，于是我先假设在不附加任何外界条件（评星和评论文本）下的产品销量是一个均值1方差1的高斯随机过程：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88kSSA.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "定义$S(t)$时间$t$为销量，$Gauss(t)$为时间$t$上的高斯过程点，此时的差分方程应该是这样：\n",
    "$$S(t)-S(t-1)=Gauss(t)-Gauss(t-1)$$\n",
    "\n",
    "可是注意到有的时候当前位置的评论信息丰度（也就是字符串长度）会对下一个时间点的销量产生一个作用，比如下面这一张图\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88kyfH.png\" width=\"600\"/>\n",
    "</center>\n",
    "红线代表字符串程度，蓝线代表销量，可以看见一个很高的红线之后蓝线处于一个被抑制的状态，但当红线下降，蓝线又开始上升。所以我们在此基础之上修正模型得到：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88eZMd.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "IA代表的就是信息丰度（字符串长度），它被限制在0-1之间，减去0.5再取倒数表明如果是高信息丰度评论则会对销量有抑制，低丰度则会提升销量。因为我们之前查看数据发现比较差劲的产品人们往往会说很多很多它的缺点、不足之处（可以扯一堆犊子），但好的产品平均下来人们只说它确实挺好。于是我做了一个实验，一开始的信息丰度比较高，为0.6，在一个时间点开始，信息丰度改为0.1，效果如下图，可以见信息丰度下来之后，销量直线上升。\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88ecLR.png\" width=\"600\"/>\n",
    "</center>\n",
    "（我这里还做了许多其他的实验，不过都没保存，也懒得重复，就先不发了）\n",
    "\n",
    "在此基础之上我们将考虑评星的效果，我认为评星$Star(t)$是附着在多项式各项上的系数项，评星越高/低则人们购买的期望越大/小，反应人们的期望，所以我将其加到了系数项上，并且人们有购买上市已久的产品的偏好，毕竟赶潮流的只是少数人，于是我会加上一个时间函数$f(t)$（实际上是不断调整意图拟合数据的结果）：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88mb3F.png\" width=\"600\"/>\n",
    "</center>\n",
    "最后调整好了参数，再模拟了不同IA和Star的情况，以及模拟信息丰度突然上升之后预测结果的变化\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88uARU.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88udot.png\" width=\"600\"/>\n",
    "</center>\n",
    "最后拟合到其中一个产品的真实情况，发现大致符合趋势，但由于随机过程的随机性，不能保证精准拟合：\n",
    "<center class=\"half\">\n",
    "    <img src=\"https://s1.ax1x.com/2020/03/15/88u2es.png\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
